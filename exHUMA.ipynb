{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08qBEEfE0gwU",
        "outputId": "317a098d-8e27-4635-e759-7791ed7ace06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset Loaded: 5087 stars found.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount drive and point to your specific path\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/duhacks/archive (1)/'\n",
        "\n",
        "# Loading the datasets (ensure filenames match exactly)\n",
        "train_df = pd.read_csv(path + 'exoTrain.csv')\n",
        "test_df = pd.read_csv(path + 'exoTest.csv')\n",
        "\n",
        "print(f\"Dataset Loaded: {train_df.shape[0]} stars found.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 1. Load Data (Assumes files from your Drive are locally accessible or in Colab)\n",
        "# train = pd.read_csv('/content/drive/MyDrive/exoTrain.csv')\n",
        "# test = pd.read_csv('/content/drive/MyDrive/exoTest.csv')\n",
        "\n",
        "def preprocess_data(df):\n",
        "    # Separate features and labels\n",
        "    x = df.drop('LABEL', axis=1)\n",
        "    y = df['LABEL'] - 1  # Convert labels 1,2 to 0,1\n",
        "\n",
        "    # Normalize features (Standardization)\n",
        "    scaler = StandardScaler()\n",
        "    x_scaled = scaler.fit_transform(x)\n",
        "\n",
        "    return x_scaled, y\n",
        "\n",
        "x_train, y_train = preprocess_data(train_df)\n",
        "x_test, y_test = preprocess_data(test_df)\n",
        "\n",
        "# 2. Address Imbalance using SMOTE\n",
        "smote = SMOTE(sampling_strategy='minority')\n",
        "x_train_res, y_train_res = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "# Reshape for 1D CNN: (samples, time_steps, features)\n",
        "x_train_res = np.reshape(x_train_res, (x_train_res.shape[0], x_train_res.shape[1], 1))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "# 3. Build the 1D CNN Architecture\n",
        "model = models.Sequential([\n",
        "    layers.Conv1D(filters=32, kernel_size=10, activation='relu', input_shape=(x_train_res.shape[1], 1)),\n",
        "    layers.MaxPooling1D(pool_size=4),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv1D(filters=64, kernel_size=10, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=4),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 4. Train the Model\n",
        "history = model.fit(x_train_res, y_train_res, epochs=20, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# 5. Evaluate Performance\n",
        "y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D-EFWd16Cij",
        "outputId": "1c54fd3e-3f18-4469-c224-758c7d8c68d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 363ms/step - accuracy: 0.6329 - loss: 0.6264 - val_accuracy: 0.3088 - val_loss: 0.7094\n",
            "Epoch 2/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 0.8126 - loss: 0.4242 - val_accuracy: 0.9912 - val_loss: 0.1613\n",
            "Epoch 3/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 395ms/step - accuracy: 0.8945 - loss: 0.3016 - val_accuracy: 0.9912 - val_loss: 0.1425\n",
            "Epoch 4/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 346ms/step - accuracy: 0.9364 - loss: 0.2059 - val_accuracy: 0.9912 - val_loss: 0.2223\n",
            "Epoch 5/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 346ms/step - accuracy: 0.9577 - loss: 0.1458 - val_accuracy: 0.9912 - val_loss: 0.1598\n",
            "Epoch 6/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 346ms/step - accuracy: 0.9712 - loss: 0.1082 - val_accuracy: 0.9912 - val_loss: 0.2301\n",
            "Epoch 7/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 341ms/step - accuracy: 0.9833 - loss: 0.0750 - val_accuracy: 0.9912 - val_loss: 0.3242\n",
            "Epoch 8/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 336ms/step - accuracy: 0.9824 - loss: 0.0636 - val_accuracy: 0.9912 - val_loss: 0.2818\n",
            "Epoch 9/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 329ms/step - accuracy: 0.8880 - loss: 0.3610 - val_accuracy: 0.9912 - val_loss: 0.2245\n",
            "Epoch 10/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 336ms/step - accuracy: 0.9800 - loss: 0.0816 - val_accuracy: 0.9912 - val_loss: 0.1898\n",
            "Epoch 11/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 343ms/step - accuracy: 0.9902 - loss: 0.0454 - val_accuracy: 0.9912 - val_loss: 0.2505\n",
            "Epoch 12/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 327ms/step - accuracy: 0.9896 - loss: 0.0638 - val_accuracy: 0.9912 - val_loss: 0.2998\n",
            "Epoch 13/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 340ms/step - accuracy: 0.9931 - loss: 0.0537 - val_accuracy: 0.9912 - val_loss: 0.3639\n",
            "Epoch 14/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 328ms/step - accuracy: 0.9950 - loss: 0.0315 - val_accuracy: 0.9912 - val_loss: 0.3539\n",
            "Epoch 15/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 343ms/step - accuracy: 0.9525 - loss: 0.2127 - val_accuracy: 0.9895 - val_loss: 0.2461\n",
            "Epoch 16/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 338ms/step - accuracy: 0.9839 - loss: 0.0910 - val_accuracy: 0.9912 - val_loss: 0.3204\n",
            "Epoch 17/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 338ms/step - accuracy: 0.9872 - loss: 0.0544 - val_accuracy: 0.9912 - val_loss: 0.3399\n",
            "Epoch 18/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 336ms/step - accuracy: 0.9929 - loss: 0.0503 - val_accuracy: 0.9912 - val_loss: 0.2654\n",
            "Epoch 19/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 328ms/step - accuracy: 0.9583 - loss: 0.1162 - val_accuracy: 0.9895 - val_loss: 0.2687\n",
            "Epoch 20/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 327ms/step - accuracy: 0.9915 - loss: 0.0510 - val_accuracy: 0.9895 - val_loss: 0.2781\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       565\n",
            "           1       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.99       570\n",
            "   macro avg       0.50      0.50      0.50       570\n",
            "weighted avg       0.98      0.99      0.99       570\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
